import re
import pandas as pd
import streamlit as st

# ================== CONFIG ==================
st.set_page_config(page_title="Ù…Ù†ØµØ© Ø£Ø·Ù„Ø³ Ø§Ù„Ø³Ù†Ø© â€“ MVP", layout="wide")
st.write("VERSION: ATLAS-CORE v0.6")

# ================== Session State ==================
if "query_text" not in st.session_state:
    st.session_state.query_text = ""

# ================== Arabic helpers ==================
AR_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652\u0670\u06D6-\u06ED]")

def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.strip()
    text = AR_DIACRITICS.sub("", text)
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def tokenize_ar(text: str):
    return normalize_ar(text).split() if text else []

def similarity_by_reference_words(reference: str, candidate: str) -> float:
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)
    if not ref_tokens:
        return 0.0
    shared = len(set(ref_tokens) & set(cand_tokens))
    return (shared / len(ref_tokens)) * 100.0

def contains_most_words(reference: str, candidate: str, threshold: float = 0.8) -> bool:
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)
    if not ref_tokens:
        return False
    shared = sum(1 for tok in ref_tokens if tok in cand_tokens)
    return (shared / len(ref_tokens)) >= threshold

# ================== Data loading ==================
@st.cache_data
def load_hadith_data():
    df = pd.read_csv("hadith_data.csv")
    needed = {"hadith_key", "source", "ref", "isnad", "matn"}
    missing = needed - set(df.columns)
    if missing:
        raise ValueError(f"Missing columns: {missing}")
    return df

df_hadith = load_hadith_data()

# ================== UI ==================
st.title("ğŸ“š Ù…Ù†ØµØ© Ø£Ø·Ù„Ø³ Ø§Ù„Ø³Ù†Ø© â€“ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ")

tab1, tab2 = st.tabs(["ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙˆØ¨Ù†Ø§Ø¡ ÙˆØ­Ø¯Ø© Ø§Ù„Ø­Ø¯ÙŠØ«", "â„¹ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù†Ù‡Ø¬ÙŠØ©"])

# ================== TAB 1 ==================
with tab1:
    st.subheader("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ Ø¹Ù† Ø§Ù„Ø­Ø¯ÙŠØ«")

    query = st.text_area(
        "Ù†Øµ Ø§Ù„Ø¨Ø­Ø« (ÙŠÙ…ÙƒÙ† Ø¥Ø¯Ø®Ø§Ù„ Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ø¯ÙŠØ« â€“ ÙƒÙ„ Ø­Ø¯ÙŠØ« ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„)",
        height=120,
        key="query_text",
        placeholder="Ù…Ø«Ø§Ù„:\nØ§Ù„Ø¯ÙŠÙ† Ø§Ù„Ù†ØµÙŠØ­Ø©\nØ¥Ù†Ù…Ø§ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø¨Ø§Ù„Ù†ÙŠØ§Øª"
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        min_sim = st.slider("Ùª Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ØªØ´Ø§Ø¨Ù‡ (Ù„Ù„Ø¨Ø­Ø« ØºÙŠØ± Ø§Ù„ØµØ§Ø±Ù…)", 10, 100, 50, 5)
    with col2:
        top_k = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ ØºÙŠØ± Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ)", 5, 200, 30, 5)
    with col3:
        atlas_mode = st.checkbox("ğŸ§­ ÙˆØ¶Ø¹ Ø§Ù„Ø£Ø·Ù„Ø³ (Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø·Ø±Ù‚)", value=True)

    strict_core = st.checkbox(
        "ğŸ”’ Ø¨Ø­Ø« Ø£Ø·Ù„Ø³ÙŠ (ÙŠØ´ØªØ±Ø· Ù†ÙˆØ§Ø© Ø§Ù„Ø­Ø¯ÙŠØ« â‰¥ 80Ùª)",
        value=True
    )

    if st.button("ğŸ§¹ Ù…Ø³Ø­ Ù†Øµ Ø§Ù„Ø¨Ø­Ø«"):
        st.session_state.query_text = ""

    if st.button("Ø§Ø¨Ø­Ø«", type="primary"):
        if not query.strip():
            st.warning("Ø§ÙƒØªØ¨ Ù†ØµÙ‹Ø§ Ù„Ù„Ø¨Ø­Ø« Ø£ÙˆÙ„Ù‹Ø§.")
        else:
            queries = [q.strip() for q in query.split("\n") if q.strip()]
            df = df_hadith.copy()

            all_results = []

            for q in queries:
                q_norm = normalize_ar(q)
                temp = df.copy()

                temp["core_match"] = temp["matn"].astype(str).apply(
                    lambda x: contains_most_words(q_norm, x, threshold=0.8)
                )

                temp["similarity"] = temp["matn"].astype(str).apply(
                    lambda x: similarity_by_reference_words(q_norm, x)
                )

                if strict_core:
                    temp = temp[temp["core_match"]]
                else:
                    temp = temp[temp["similarity"] >= float(min_sim)]

                all_results.append(temp)

            results = pd.concat(all_results).drop_duplicates()

            if not atlas_mode:
                results = results.sort_values(
                    ["similarity"],
                    ascending=False
                ).head(int(top_k))
            else:
                results = results.sort_values(["hadith_key", "ref"])

            if results.empty:
                st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©.")
            else:
                st.success(
                    f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ø±ÙˆØ§ÙŠØ© Ø¶Ù…Ù† "
                    f"{results['hadith_key'].nunique()} ÙˆØ­Ø¯Ø© Ø­Ø¯ÙŠØ«ÙŠØ© Ø£Ø·Ù„Ø³ÙŠØ©."
                )

                for hadith_key, grp in results.groupby("hadith_key"):
                    with st.expander(
                        f"ğŸ§­ ÙˆØ­Ø¯Ø© Ø­Ø¯ÙŠØ« Ø£Ø·Ù„Ø³ÙŠØ©: {hadith_key} | Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø±Ù‚: {len(grp)}",
                        expanded=True
                    ):
                        st.markdown("### ğŸ“Œ Ø§Ù„Ù…ØªÙ† Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Raw)")
                        st.write(grp.iloc[0]["matn"])

                        st.markdown("### ğŸ§¾ Ø§Ù„Ø·Ø±Ù‚ ÙˆØ§Ù„Ø±ÙˆØ§ÙŠØ§Øª")
                        for _, r in grp.iterrows():
                            st.markdown(
                                f"- **Ø§Ù„Ù…ØµØ¯Ø±:** {r['source']} | **Ø§Ù„Ù…Ø±Ø¬Ø¹:** {r['ref']}\n"
                                f"  - **Ø§Ù„Ø³Ù†Ø¯ (Raw):** {r['isnad']}\n"
                                f"  - **Ø§Ù„Ù…ØªÙ† (Raw):** {r['matn']}"
                            )

# ================== TAB 2 ==================
with tab2:
    st.info(
        "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØµØ© Ø£Ø¯Ø§Ø© ØªØ­Ø¶ÙŠØ± Ø£Ø·Ù„Ø³ÙŠØ©:\n"
        "- Ù„Ø§ ØªÙØµØ¯Ø± Ø£Ø­ÙƒØ§Ù…Ù‹Ø§ Ø­Ø¯ÙŠØ«ÙŠØ©\n"
        "- Ù„Ø§ ØªÙØµÙ„ Ø§Ù„Ø³Ù†Ø¯ ÙˆØ§Ù„Ù…ØªÙ† Ø¢Ù„ÙŠÙ‹Ø§\n"
        "- ØªÙØ³ØªØ®Ø¯Ù… Ù„Ø¨Ù†Ø§Ø¡ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ø­Ø¯ÙŠØ« Ø§Ù„Ø£Ø·Ù„Ø³ÙŠØ©\n\n"
        "Ø§Ù„Ù†Øµ ÙŠØ¨Ù‚Ù‰ Ù…Ø­ÙÙˆØ¸Ù‹Ø§ Ø¹Ù†Ø¯ ØªØºÙŠÙŠØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª."
    )
