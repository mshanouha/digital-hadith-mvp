import re
import pandas as pd
import streamlit as st

# ======================================================
# CONFIG
# ======================================================
st.set_page_config(page_title="Ø£Ø·Ù„Ø³ Ø§Ù„Ø³Ù†Ø© â€“ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ", layout="wide")
st.write("VERSION: ATLAS-HADITH v1.1")

# ======================================================
# SESSION STATE
# ======================================================
if "page" not in st.session_state:
    st.session_state.page = "search"

if "active_hadith" not in st.session_state:
    st.session_state.active_hadith = None

if "query_text" not in st.session_state:
    st.session_state.query_text = ""

def go_to_analysis(hadith_key):
    st.session_state.active_hadith = hadith_key
    st.session_state.page = "analysis"

def go_to_search():
    st.session_state.page = "search"

# ======================================================
# ARABIC NORMALIZATION
# ======================================================
AR_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652\u0670\u06D6-\u06ED]")

def normalize_ar(text):
    if not text:
        return ""
    text = AR_DIACRITICS.sub("", str(text))
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    return re.sub(r"\s+", " ", text).strip()

def tokenize_ar(text):
    return normalize_ar(text).split()

def contains_core(reference, candidate):
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)

    if not ref_tokens:
        return False

    shared = sum(1 for tok in ref_tokens if tok in cand_tokens)

    if len(ref_tokens) <= 4:
        return shared == len(ref_tokens)

    return (shared / len(ref_tokens)) >= 0.8

# ======================================================
# DATA
# ======================================================
@st.cache_data
def load_data():
    df = pd.read_csv("hadith_data.csv")
    return df

df_hadith = load_data()

# ======================================================
# SCORING & VISUALS
# ======================================================
def score_label(score):
    if score >= 9:
        return "Ù‚ÙˆÙŠ Ø¬Ø¯Ù‹Ø§"
    elif score >= 7:
        return "Ù‚ÙˆÙŠ"
    elif score >= 5:
        return "Ù…ØªÙˆØ³Ø·"
    elif score >= 3:
        return "Ø¶Ø¹ÙŠÙ"
    else:
        return "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"

def hadith_global_score(scores):
    if not scores:
        return 0
    max_score = max(scores)
    avg_score = sum(scores) / len(scores)
    strong = len([s for s in scores if s >= 7])
    final = (0.5 * max_score) + (0.3 * avg_score) + (0.2 * strong)
    return round(min(final, 10), 1)

def hadith_description(score):
    if score >= 9:
        return "Ø­Ø¯ÙŠØ« Ø«Ø§Ø¨Øª Ù‚ÙˆÙŠ Ø¬Ø¯Ù‹Ø§"
    elif score >= 7:
        return "Ø­Ø¯ÙŠØ« ØµØ­ÙŠØ­ Ù‚ÙˆÙŠ"
    elif score >= 5:
        return "Ø­Ø¯ÙŠØ« Ø­Ø³Ù† Ø£Ùˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙˆØ©"
    elif score >= 3:
        return "Ø­Ø¯ÙŠØ« Ø¶Ø¹ÙŠÙ"
    else:
        return "Ø­Ø¯ÙŠØ« Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"

def render_color_bar(score):
    colors = [
        "#d73027", "#f46d43", "#fdae61", "#fee08b",
        "#ffffbf", "#d9ef8b", "#a6d96a", "#66bd63",
        "#1a9850", "#006837"
    ]
    active = int(round(score)) - 1
    blocks = ""
    for i, c in enumerate(colors):
        opacity = "1" if i <= active else "0.25"
        blocks += f"""
        <div style="
            width:28px;
            height:16px;
            margin:2px;
            background:{c};
            opacity:{opacity};
            display:inline-block;
            border-radius:4px;">
        </div>
        """
    st.markdown(blocks, unsafe_allow_html=True)

# ======================================================
# PAGE: SEARCH
# ======================================================
if st.session_state.page == "search":

    st.title("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ Ø¹Ù† Ø§Ù„Ø­Ø¯ÙŠØ«")

    query = st.text_area(
        "Ù†Øµ Ø§Ù„Ø¨Ø­Ø« (ÙƒÙ„ Ø­Ø¯ÙŠØ« ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„)",
        height=120,
        key="query_text",
        placeholder="Ù…Ø«Ø§Ù„:\nØ¥Ù†Ù…Ø§ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø¨Ø§Ù„Ù†ÙŠØ§Øª\nÙ…Ù† ÙƒØ°Ø¨ Ø¹Ù„ÙŠ Ù…ØªØ¹Ù…Ø¯Ø§"
    )

    strict_core = st.checkbox("ğŸ”’ Ø¨Ø­Ø« Ø£Ø·Ù„Ø³ÙŠ ØµØ§Ø±Ù… (Ù†ÙˆØ§Ø© Ø§Ù„Ø­Ø¯ÙŠØ« â‰¥ 80Ùª)", value=True)

    if st.button("Ø§Ø¨Ø­Ø«", type="primary"):
        if not query.strip():
            st.warning("Ø§ÙƒØªØ¨ Ù†Øµ Ø§Ù„Ø¨Ø­Ø« Ø£ÙˆÙ„Ù‹Ø§")
        else:
            queries = [q.strip() for q in query.split("\n") if q.strip()]
            results = []

            for q in queries:
                temp = df_hadith.copy()
                temp["match"] = temp["matn"].apply(lambda x: contains_core(q, x))
                if strict_core:
                    temp = temp[temp["match"]]
                results.append(temp)

            results = pd.concat(results).drop_duplicates()

            if results.empty:
                st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬")
            else:
                st.success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {results['hadith_key'].nunique()} ÙˆØ­Ø¯Ø© Ø­Ø¯ÙŠØ«ÙŠØ©")

                for hadith_key, grp in results.groupby("hadith_key"):
                    with st.expander(f"ğŸ§­ ÙˆØ­Ø¯Ø© Ø­Ø¯ÙŠØ«: {hadith_key}", expanded=False):
                        st.write("ğŸ“Œ Ø§Ù„Ù…ØªÙ† Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:")
                        st.write(grp.iloc[0]["matn"])
                        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª: {len(grp)}")
                        st.button(
                            "ğŸ” Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ",
                            key=f"analyze_{hadith_key}",
                            on_click=go_to_analysis,
                            args=(hadith_key,)
                        )

# ======================================================
# PAGE: ANALYSIS
# ======================================================
if st.session_state.page == "analysis":

    hadith_key = st.session_state.active_hadith
    st.title(f"ğŸ§­ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ â€“ {hadith_key}")

    data = df_hadith[df_hadith["hadith_key"] == hadith_key]

    st.subheader("ğŸ“Œ Ø§Ù„Ù†Øµ Ø§Ù„Ù†ÙˆÙˆÙŠ")
    st.write(data.iloc[0]["matn"])

    st.markdown("---")
    st.subheader("ğŸ§µ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ø³Ù†Ø¯ÙŠØ© (Ø·Ø±Ù‚ Ø­Ù‚ÙŠÙ‚ÙŠØ©)")

    scores = []

    for isnad, group in data.groupby("isnad"):
        st.markdown(f"**Ø§Ù„Ø³Ù†Ø¯:** {isnad}")
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§ÙŠØ§Øª ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø·Ø±ÙŠÙ‚: {len(group)}")

        score = st.slider(
            "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ (0â€“10)",
            0, 10, 7,
            key=f"score_{isnad}"
        )

        st.write(f"Ø§Ù„ØªÙˆØµÙŠÙ: {score_label(score)}")
        scores.append(score)
        st.markdown("---")

    final_score = hadith_global_score(scores)

    st.subheader("ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø­Ø¯ÙŠØ«")
    st.write(f"Ø§Ù„Ø¯Ø±Ø¬Ø©: {final_score} / 10")
    render_color_bar(final_score)
    st.write(hadith_description(final_score))

    st.markdown("---")
    verdict = st.selectbox(
        "Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ",
        ["ØµØ­ÙŠØ­ Ù‚Ø·Ø¹ÙŠ", "ØµØ­ÙŠØ­", "Ø­Ø³Ù†", "Ù…Ø®ØªÙ„Ù ÙÙŠÙ‡", "Ø¶Ø¹ÙŠÙ"]
    )

    notes = st.text_area("ğŸ“ Ø®Ù„Ø§ØµØ© Ø§Ù„ØªØ­Ù‚ÙŠÙ‚")

    if st.button("â†©ï¸ Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø«"):
        go_to_search()
