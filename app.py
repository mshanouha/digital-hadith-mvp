import re
import pandas as pd
import streamlit as st
st.write("VERSION: TAB-SEARCH v0.2")
st.set_page_config(page_title="ููุตุฉ ุงูุชุญููู ุงูุฑููู - MVP", layout="wide")

# ----------------- Arabic helpers -----------------
AR_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652\u0670\u06D6-\u06ED]")

def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.strip()
    text = AR_DIACRITICS.sub("", text)
    text = text.replace("ุฃ", "ุง").replace("ุฅ", "ุง").replace("ุข", "ุง")
    text = text.replace("ู", "ู").replace("ุฉ", "ู")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def tokenize_ar(text: str):
    return normalize_ar(text).split() if text else []

def similarity_by_reference_words(reference: str, candidate: str) -> float:
    """
    Similarity% = (ุงููููุงุช ุงููุดุชุฑูุฉ รท ูููุงุช ุงููุชู ุงููุฑุฌุนู) ร 100
    MVP: ุชูุงุทุน ูุฌููุนุงุช ูููุงุช (unique overlap)
    """
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)
    if not ref_tokens:
        return 0.0
    ref_set = set(ref_tokens)
    cand_set = set(cand_tokens)
    shared = len(ref_set.intersection(cand_set))
    total = len(ref_set)
    return (shared / total) * 100.0

# ----------------- Data loading -----------------
@st.cache_data
def load_hadith_data():
    """
    Loads hadith data from hadith_data.csv if exists.
    If not exists, uses a tiny built-in sample so the app works immediately.
    """
    try:
        df = pd.read_csv("hadith_data.csv")
        # expected columns
        needed = {"hadith_key", "source", "ref", "isnad", "matn"}
        missing = needed - set(df.columns)
        if missing:
            raise ValueError(f"Missing columns in hadith_data.csv: {missing}")
        return df
    except Exception:
        # fallback tiny sample
        sample = [
            {
                "hadith_key": "H001",
                "source": "ุนููุฉ",
                "ref": "1",
                "isnad": "ููุงู ุนู ููุงู ุนู ุนุฑูุฌู",
                "matn": "ุงุตูุจ ุงููู ูุงุชุฎุฐ ุงููุง ูู ูุฑู ูุงูุชู ุนููู ูุงูุฑู ุงููุจู ุงู ูุชุฎุฐ ุงููุง ูู ุฐูุจ"
            },
            {
                "hadith_key": "H001",
                "source": "ุนููุฉ",
                "ref": "2",
                "isnad": "ููุงู ุนู ููุงู ุนู ุนุฑูุฌู (ุทุฑูู ุขุฎุฑ)",
                "matn": "ุงุตูุจ ุงููู ูุงุชุฎุฐ ุงููุง ูู ูุฑู ูุงูุชู ุนููู ูุงูุฑ ุงููุจู ุงู ูุชุฎุฐ ุงููุง ูู ุฐูุจ"
            },
            {
                "hadith_key": "H002",
                "source": "ุนููุฉ",
                "ref": "3",
                "isnad": "ููุงู ุนู ููุงู",
                "matn": "ุงููุง ุงูุงุนูุงู ุจุงูููุงุช ูุงููุง ููู ุงูุฑุฆ ูุง ููู"
            },
        ]
        return pd.DataFrame(sample)

df_hadith = load_hadith_data()

# ----------------- UI -----------------
st.title("๐ ููุตุฉ ุงูุชุญููู ุงูุฑููู ููุฅุณูุงุฏ ูุงููุชู โ MVP")

tab1, tab2, tab3 = st.tabs(["๐ ุงูุจุญุซ ุนู ุงูุญุฏูุซ", "๐งพ ุชูููู ุงูุฑูุงุฉ (ููุฏ ุงูุชุทููุฑ)", "๐ฆ ุงููุชุจ ุงูุญุฏูุซูุฉ (ููุฏ ุงูุชุทููุฑ)"])

# ============ TAB 1: SEARCH ============
with tab1:
    st.subheader("๐ ุงูุจุญุซ ุนู ุงูุญุฏูุซ ุจูู ุทุฑูู")
    st.caption("ุงูุชุจ ุงููุชู (ุฃู ุฌุฒุกูุง ููู). ุณูุนุฑุถ ุงููุธุงู ุงููุชุงุฆุฌ ุงูุฃูุฑุจุ ููุฌูุน ุงูุทุฑู ุงููุชุนุฏุฏุฉ ุชุญุช ููุณ ุงูุญุฏูุซ.")

    query = st.text_area("ูุต ุงูุจุญุซ (ุงููุชู)", height=120, placeholder="ูุซุงู: ุฃุตูุจ ุฃููู ูุงุชุฎุฐ ุฃูููุง ูู ูุฑู...")

    colA, colB, colC = st.columns(3)
    with colA:
        min_sim = st.slider("ุงูุญุฏ ุงูุฃุฏูู ููุชุดุงุจู %", 10, 100, 50, 5)
    with colB:
        top_k = st.slider("ุนุฏุฏ ุงููุชุงุฆุฌ (ุงูุทุฑู) ุงููุนุฑูุถุฉ", 5, 200, 30, 5)
    with colC:
        group_view = st.checkbox("ุชุฌููุน ุงููุชุงุฆุฌ ุญุณุจ ุงูุญุฏูุซ (ุนุฑุถ ูู ุงูุทุฑู)", value=True)

    if st.button("ุงุจุญุซ", type="primary"):
        q = query.strip()
        if not q:
            st.warning("ุงูุชุจ ูุตูุง ููุจุญุซ ุฃูููุง.")
        else:
            # compute similarity against each matn row
            sims = []
            q_norm = normalize_ar(q)
            for idx, row in df_hadith.iterrows():
                matn = str(row["matn"])
                sim = similarity_by_reference_words(q_norm, matn)
                sims.append(sim)

            results = df_hadith.copy()
            results["similarity"] = sims
            results = results.sort_values("similarity", ascending=False)

            # filter and limit
            results = results[results["similarity"] >= float(min_sim)].head(int(top_k))

            if results.empty:
                st.error("ูุง ุชูุฌุฏ ูุชุงุฆุฌ ุถูู ุญุฏ ุงูุชุดุงุจู ุงููุญุฏุฏ. ุฌุฑูุจ ุชุฎููุถ ุงูุญุฏ ุงูุฃุฏูู.")
            else:
                st.success(f"ุชู ุงูุนุซูุฑ ุนูู {len(results)} ุทุฑูู/ุฑูุงูุฉ ุถูู ุงูุชุดุงุจู โฅ {min_sim}%")

                if group_view:
                    # group by hadith_key to show all paths
                    for hadith_key, grp in results.groupby("hadith_key"):
                        best = grp.iloc[0]
                        header = f"ุญุฏูุซ: {hadith_key} โ ุฃูุถู ุชุดุงุจู: {best['similarity']:.2f}%"
                        with st.expander(header, expanded=True):
                            st.write(f"**ุงููุชู (ุฃูุฑุจ ูุชูุฌุฉ):** {best['matn']}")
                            st.write(f"**ุนุฏุฏ ุงูุทุฑู ุงููุนุฑูุถุฉ ููุฐุง ุงูุญุฏูุซ:** {len(grp)}")
                            st.divider()
                            for _, r in grp.iterrows():
                                st.markdown(
                                    f"- **ุงููุตุฏุฑ:** {r['source']} | **ุงููุฑุฌุน:** {r['ref']} | **ุงูุชุดุงุจู:** {r['similarity']:.2f}%\n"
                                    f"  - **ุงูุณูุฏ:** {r['isnad']}\n"
                                    f"  - **ุงููุชู:** {r['matn']}"
                                )
                else:
                    # flat view
                    for _, r in results.iterrows():
                        st.markdown(
                            f"**{r['source']} โ {r['ref']}** | ุงูุชุดุงุจู: **{r['similarity']:.2f}%**\n\n"
                            f"- ุงูุณูุฏ: {r['isnad']}\n"
                            f"- ุงููุชู: {r['matn']}\n"
                            "---"
                        )

    st.divider()
    st.info(
        "๐ ูุฅุถุงูุฉ ุจูุงูุงุชู ุงูุญููููุฉ: ุถุน ููู ุจุงุณู **hadith_data.csv** ุฏุงุฎู ุงููุณุชูุฏุน ุจููุณ ุงูุฃุนูุฏุฉ:\n"
        "`hadith_key, source, ref, isnad, matn`\n"
        "ูุณูุนุชูุฏ ุนููู ุงูุชุทุจูู ุชููุงุฆููุง."
    )

# ============ TAB 2 Placeholder ============
with tab2:
    st.subheader("๐งพ ุชูููู ุงูุฑูุงุฉ (ููุฏ ุงูุชุทููุฑ)")
    st.write("ุณูุถูู ููุง ูุงุญููุง: ุชูููู ุงูุฑูุงุฉ ููู ุทุฑูู + ุงููุชูุฌุฉ ุงููุฑูุจุฉ + ููุงุฑูุฉ ุงูุทุฑู.")

# ============ TAB 3 Placeholder ============
with tab3:
    st.subheader("๐ฆ ุงููุชุจ ุงูุญุฏูุซูุฉ (ููุฏ ุงูุชุทููุฑ)")
    st.write("ุณูุถูู ููุง ูุงุญููุง: ุจุทุงูุฉ ุงููุชุงุจ ุงูุญุฏูุซูุฉ ูุงูุฅุญุตุงุกุงุช (ุนุฏุฏ ุงูุฃุญุงุฏูุซ/ุงูุฃุณุงููุฏ/ุงููุชูู/ุงูููุฑุฑ...).")

