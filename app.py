import re
import pandas as pd
import streamlit as st

st.set_page_config(page_title="ููุตุฉ ุงูุชุญููู ุงูุฑููู - MVP", layout="wide")
st.write("VERSION: TAB-SEARCH v0.2")
# ----------------- Arabic helpers -----------------
AR_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652\u0670\u06D6-\u06ED]")

def normalize_ar(text: str) -> str:
    if not text:
        return ""
    text = text.strip()
    text = AR_DIACRITICS.sub("", text)
    text = text.replace("ุฃ", "ุง").replace("ุฅ", "ุง").replace("ุข", "ุง")
    text = text.replace("ู", "ู").replace("ุฉ", "ู")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def tokenize_ar(text: str):
    return normalize_ar(text).split() if text else []

def similarity_by_reference_words(reference: str, candidate: str) -> float:
    """
    Similarity% = (ุงููููุงุช ุงููุดุชุฑูุฉ รท ูููุงุช ุงููุชู ุงููุฑุฌุนู) ร 100
    MVP: ุชูุงุทุน ูุฌููุนุงุช ูููุงุช (unique overlap)
    """
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)
    if not ref_tokens:
        return 0.0
    ref_set = set(ref_tokens)
    cand_set = set(cand_tokens)
    shared = len(ref_set.intersection(cand_set))
    total = len(ref_set)
    return (shared / total) * 100.0

# ----------------- Data loading -----------------
@st.cache_data
def load_hadith_data():
    """
    Loads hadith data from hadith_data.csv if exists.
    If not exists, uses a tiny built-in sample so the app works immediately.
    """
    try:
        df = pd.read_csv("hadith_data.csv")
        # expected columns
        needed = {"hadith_key", "source", "ref", "isnad", "matn"}
        missing = needed - set(df.columns)
        if missing:
            raise ValueError(f"Missing columns in hadith_data.csv: {missing}")
        return df
    except Exception:
        # fallback tiny sample
        sample = [
            {
                "hadith_key": "H001",
                "source": "ุนููุฉ",
                "ref": "1",
                "isnad": "ููุงู ุนู ููุงู ุนู ุนุฑูุฌู",
                "matn": "ุงุตูุจ ุงููู ูุงุชุฎุฐ ุงููุง ูู ูุฑู ูุงูุชู ุนููู ูุงูุฑู ุงููุจู ุงู ูุชุฎุฐ ุงููุง ูู ุฐูุจ"
            },
            {
                "hadith_key": "H001",
                "source": "ุนููุฉ",
                "ref": "2",
                "isnad": "ููุงู ุนู ููุงู ุนู ุนุฑูุฌู (ุทุฑูู ุขุฎุฑ)",
                "matn": "ุงุตูุจ ุงููู ูุงุชุฎุฐ ุงููุง ูู ูุฑู ูุงูุชู ุนููู ูุงูุฑ ุงููุจู ุงู ูุชุฎุฐ ุงููุง ูู ุฐูุจ"
            },
            {
                "hadith_key": "H002",
                "source": "ุนููุฉ",
                "ref": "3",
                "isnad": "ููุงู ุนู ููุงู",
                "matn": "ุงููุง ุงูุงุนูุงู ุจุงูููุงุช ูุงููุง ููู ุงูุฑุฆ ูุง ููู"
            },
        ]
        return pd.DataFrame(sample)

df_hadith = load_hadith_data()

# ----------------- UI -----------------
st.title("๐ ููุตุฉ ุงูุชุญููู ุงูุฑููู ููุฅุณูุงุฏ ูุงููุชู โ MVP")

tab1, tab2, tab3 = st.tabs(["๐ ุงูุจุญุซ ุนู ุงูุญุฏูุซ", "๐งพ ุชูููู ุงูุฑูุงุฉ (ููุฏ ุงูุชุทููุฑ)", "๐ฆ ุงููุชุจ ุงูุญุฏูุซูุฉ (ููุฏ ุงูุชุทููุฑ)"])

# ============ TAB 1: SEARCH ============

with tab1:
    st.subheader("๐ ุงูุจุญุซ ุนู ุงูุญุฏูุซ ุจูู ุทุฑูู")
    st.caption("ุงูุชุจ ุงููุชู (ุฃู ุฌุฒุกูุง ููู). ุณูุนุฑุถ ุงููุธุงู ุงููุชุงุฆุฌ ุงูุฃูุฑุจุ ููุฌูุน ุงูุทุฑู ุงููุชุนุฏุฏุฉ ุชุญุช ููุณ ุงูุญุฏูุซ.")

    query = st.text_area(
        "ูุต ุงูุจุญุซ (ุงููุชู)",
        height=120,
        placeholder="ูุซุงู: ุฃุตูุจ ุฃููู ูุงุชุฎุฐ ุฃูููุง ูู ูุฑู..."
    )

    colA, colB, colC = st.columns(3)

    with colA:
        min_sim = st.slider("ูช ุงูุญุฏ ุงูุฃุฏูู ููุชุดุงุจู", 10, 100, 50, 5)

    with colB:
        top_k = st.slider("ุนุฏุฏ ุงููุชุงุฆุฌ (ุงูุทุฑู) ุงููุนุฑูุถุฉ", 5, 200, 30, 5)

    with colC:
        group_view = st.checkbox("ุชุฌููุน ุงููุชุงุฆุฌ ุญุณุจ ุงูุญุฏูุซ (ุนุฑุถ ูู ุงูุทุฑู)", value=True)

    search_mode = st.selectbox(
        "ุทุฑููุฉ ุงูุจุญุซ",
        ["ุงูุงุซููู ูุนูุง (ุฃูุถู)", "ุงุญุชูุงุก ุงููุต", "ุชุดุงุจู ุจุงููููุงุช"],
        index=0
    )

    sources = sorted(df_hadith["source"].astype(str).unique().tolist())
    source_filter = st.multiselect("ุงุฎุชุฑ ุงููุตุฏุฑ/ุงููุชุงุจ", sources, default=sources)

    if st.button("ุงุจุญุซ", type="primary"):
        q = query.strip()
        if not q:
            st.warning("ุงูุชุจ ูุตูุง ููุจุญุซ ุฃูููุง.")
        else:
            from rapidfuzz import fuzz

            q_norm = normalize_ar(q)
            df = df_hadith.copy()

            if source_filter:
                df = df[df["source"].astype(str).isin(source_filter)]

            df["matn_norm"] = df["matn"].astype(str).apply(normalize_ar)
            df["contains"] = df["matn_norm"].apply(lambda x: q_norm in x)
            df["fuzzy"] = df["matn_norm"].apply(lambda x: fuzz.token_set_ratio(q_norm, x))
            df["similarity"] = df["matn"].astype(str).apply(
                lambda x: similarity_by_reference_words(q_norm, x)
            )

            if search_mode == "ุงุญุชูุงุก ุงููุต":
                results = df[df["contains"]]
            elif search_mode == "ุชุดุงุจู ุจุงููููุงุช":
                results = df[df["similarity"] >= float(min_sim)]
            else:
                results = df[(df["contains"]) | (df["similarity"] >= float(min_sim))]

            results = results.sort_values(
                ["contains", "fuzzy", "similarity"],
                ascending=[False, False, False]
            ).head(int(top_k))

            if results.empty:
                st.error("ูุง ุชูุฌุฏ ูุชุงุฆุฌ. ุฌุฑูุจ ุชุบููุฑ ุงููููุงุช ุฃู ุชุฎููุถ ุญุฏ ุงูุชุดุงุจู.")
            else:
                st.success(f"ุชู ุงูุนุซูุฑ ุนูู {len(results)} ูุชูุฌุฉ (ุทุฑูู/ุฑูุงูุฉ).")

                for hadith_key, grp in results.groupby("hadith_key"):
                    best = grp.iloc[0]
                    with st.expander(
                        f"ุญุฏูุซ: {hadith_key} โ Fuzzy: {best['fuzzy']:.0f}% โ ุชุดุงุจู ูููุงุช: {best['similarity']:.0f}%",
                        expanded=True
                    ):
                        st.write(f"**ุงููุชู:** {best['matn']}")
                        for _, r in grp.iterrows():
                            st.markdown(
                                f"- **ุงููุตุฏุฑ:** {r['source']} | **ุงููุฑุฌุน:** {r['ref']}\n"
                                f"  - **ุงูุณูุฏ:** {r['isnad']}"
                            )

    st.divider()
    st.info(
        "๐ ูุฅุถุงูุฉ ุจูุงูุงุชู ุงูุญููููุฉ: ุถุน ููู ุจุงุณู **hadith_data.csv** ุฏุงุฎู ุงููุณุชูุฏุน ุจููุณ ุงูุฃุนูุฏุฉ:\n"
        "`hadith_key, source, ref, isnad, matn`"
    )


# ============ TAB 2 Placeholder ============
with tab2:
    st.subheader("๐งพ ุชูููู ุงูุฑูุงุฉ (ููุฏ ุงูุชุทููุฑ)")
    st.write("ุณูุถูู ููุง ูุงุญููุง: ุชูููู ุงูุฑูุงุฉ ููู ุทุฑูู + ุงููุชูุฌุฉ ุงููุฑูุจุฉ + ููุงุฑูุฉ ุงูุทุฑู.")

# ============ TAB 3 Placeholder ============
with tab3:
    st.subheader("๐ฆ ุงููุชุจ ุงูุญุฏูุซูุฉ (ููุฏ ุงูุชุทููุฑ)")
    st.write("ุณูุถูู ููุง ูุงุญููุง: ุจุทุงูุฉ ุงููุชุงุจ ุงูุญุฏูุซูุฉ ูุงูุฅุญุตุงุกุงุช (ุนุฏุฏ ุงูุฃุญุงุฏูุซ/ุงูุฃุณุงููุฏ/ุงููุชูู/ุงูููุฑุฑ...).")










