import re
import pandas as pd
import streamlit as st

# ======================================================
# CONFIG
# ======================================================
st.set_page_config(page_title="Ø£Ø·Ù„Ø³ Ø§Ù„Ø³Ù†Ø© â€“ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ", layout="wide")
st.write("VERSION: ATLAS-HADITH v1.3")

# ======================================================
# SESSION STATE
# ======================================================
if "page" not in st.session_state:
    st.session_state.page = "search"

if "active_hadith" not in st.session_state:
    st.session_state.active_hadith = None

def go_to_analysis(hadith_key):
    st.session_state.active_hadith = hadith_key
    st.session_state.page = "analysis"

def go_to_search():
    st.session_state.page = "search"

# ======================================================
# ARABIC NORMALIZATION
# ======================================================
AR_DIACRITICS = re.compile(r"[\u0617-\u061A\u064B-\u0652\u0670\u06D6-\u06ED]")

def normalize_ar(text):
    if not text:
        return ""
    text = AR_DIACRITICS.sub("", str(text))
    text = text.replace("Ø£", "Ø§").replace("Ø¥", "Ø§").replace("Ø¢", "Ø§")
    text = text.replace("Ù‰", "ÙŠ").replace("Ø©", "Ù‡")
    text = re.sub(r"[^\w\s\u0600-\u06FF]", " ", text)
    return re.sub(r"\s+", " ", text).strip()

def tokenize_ar(text):
    return normalize_ar(text).split()

# ======================================================
# ISNAD NORMALIZATION
# ======================================================
def normalize_isnad(isnad):
    if not isnad or pd.isna(isnad):
        return None
    isnad = normalize_ar(isnad)
    for w in ["Ø­Ø¯Ø«Ù†Ø§", "Ø§Ø®Ø¨Ø±Ù†Ø§", "Ù‚Ø§Ù„", "Ø³Ù…Ø¹Øª", "Ø¹Ù†"]:
        isnad = isnad.replace(w, "")
    isnad = re.sub(r"\s+", " ", isnad)
    return isnad.strip()

# ======================================================
# CORE MATCHING
# ======================================================
def contains_core(reference, candidate):
    ref_tokens = tokenize_ar(reference)
    cand_tokens = tokenize_ar(candidate)
    if not ref_tokens:
        return False
    shared = sum(1 for tok in ref_tokens if tok in cand_tokens)
    if len(ref_tokens) <= 4:
        return shared == len(ref_tokens)
    return (shared / len(ref_tokens)) >= 0.8

# ======================================================
# DATA
# ======================================================
@st.cache_data
def load_data():
    df = pd.read_csv("hadith_data.csv")
    df["isnad_norm"] = df["isnad"].apply(normalize_isnad)
    df = df[df["isnad_norm"].notna()]
    return df

df = load_data()

# ======================================================
# SCORING & VISUALS
# ======================================================
def score_label(score):
    if score >= 9:
        return "Ù‚ÙˆÙŠ Ø¬Ø¯Ù‹Ø§"
    elif score >= 7:
        return "Ù‚ÙˆÙŠ"
    elif score >= 5:
        return "Ù…ØªÙˆØ³Ø·"
    elif score >= 3:
        return "Ø¶Ø¹ÙŠÙ"
    else:
        return "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"

def hadith_global_score(scores):
    if not scores:
        return None
    max_score = max(scores)
    avg_score = sum(scores) / len(scores)
    n = len(scores)
    reference_bonus = 1 if (n == 1 and max_score >= 8) else 0
    final = (
        0.6 * max_score +
        0.3 * avg_score +
        0.1 * min(n, 5) +
        reference_bonus
    )
    return round(min(final, 10), 1)

def hadith_description(score):
    if score >= 9:
        return "Ø­Ø¯ÙŠØ« Ø«Ø§Ø¨Øª Ù‚ÙˆÙŠ Ø¬Ø¯Ù‹Ø§"
    elif score >= 7:
        return "Ø­Ø¯ÙŠØ« ØµØ­ÙŠØ­ Ù‚ÙˆÙŠ"
    elif score >= 5:
        return "Ø­Ø¯ÙŠØ« Ø­Ø³Ù† Ø£Ùˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙˆØ©"
    elif score >= 3:
        return "Ø­Ø¯ÙŠØ« Ø¶Ø¹ÙŠÙ"
    else:
        return "Ø­Ø¯ÙŠØ« Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"

def render_color_bar(score):
    colors = [
        "#d73027", "#f46d43", "#fdae61", "#fee08b",
        "#ffffbf", "#d9ef8b", "#a6d96a", "#66bd63",
        "#1a9850", "#006837"
    ]
    active = int(round(score)) - 1
    blocks = ""
    for i, c in enumerate(colors):
        opacity = "1" if i <= active else "0.25"
        blocks += f"""
        <div style="
            width:26px;
            height:14px;
            margin:2px;
            background:{c};
            opacity:{opacity};
            display:inline-block;
            border-radius:4px;">
        </div>
        """
    st.markdown(blocks, unsafe_allow_html=True)

# ======================================================
# PAGE: SEARCH
# ======================================================
if st.session_state.page == "search":

    st.title("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ Ø¹Ù† Ø§Ù„Ø­Ø¯ÙŠØ«")
    query = st.text_area("Ù†Øµ Ø§Ù„Ø¨Ø­Ø« (ÙƒÙ„ Ø­Ø¯ÙŠØ« ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„)", height=120)

    if st.button("Ø§Ø¨Ø­Ø«", type="primary"):
        if not query.strip():
            st.warning("Ø§ÙƒØªØ¨ Ù†Øµ Ø§Ù„Ø¨Ø­Ø« Ø£ÙˆÙ„Ù‹Ø§")
        else:
            results = []
            for q in query.split("\n"):
                q = q.strip()
                if not q:
                    continue
                temp = df.copy()
                temp["match"] = temp["matn"].apply(lambda x: contains_core(q, x))
                temp = temp[temp["match"]]
                results.append(temp)

            results = pd.concat(results).drop_duplicates()
            if results.empty:
                st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬")
            else:
                for key, grp in results.groupby("hadith_key"):
                    with st.expander(f"ğŸ§­ ÙˆØ­Ø¯Ø© Ø­Ø¯ÙŠØ«: {key}"):
                        st.write(grp.iloc[0]["matn"])
                        st.button(
                            "ğŸ” Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚",
                            key=f"an_{key}",
                            on_click=go_to_analysis,
                            args=(key,)
                        )

# ======================================================
# PAGE: ANALYSIS
# ======================================================
if st.session_state.page == "analysis":

    key = st.session_state.active_hadith
    data = df[df["hadith_key"] == key]

    st.title(f"ğŸ§­ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ â€“ {key}")
    st.write(data.iloc[0]["matn"])

    st.markdown("---")
    st.subheader("ğŸ§µ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ø³Ù†Ø¯ÙŠØ©")

    scores = []

    for isnad, grp in data.groupby("isnad_norm"):
        st.markdown(f"**Ø§Ù„Ø³Ù†Ø¯:** {isnad}")
        score = st.selectbox(
            "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚",
            list(range(0, 11)),
            index=7,
            key=f"score_{isnad}"
        )
        render_color_bar(score)
        st.write(f"Ø§Ù„ØªÙˆØµÙŠÙ: {score_label(score)}")
        scores.append(score)
        st.markdown("---")

    final = hadith_global_score(scores)

    if final is None:
        st.warning("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    else:
        st.subheader("ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø­Ø¯ÙŠØ«")
        st.write(f"Ø§Ù„Ø¯Ø±Ø¬Ø©: {final} / 10")
        render_color_bar(final)
        st.write(hadith_description(final))

    st.markdown("---")
    st.selectbox("Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ø­Ø¯ÙŠØ«ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", ["ØµØ­ÙŠØ­ Ù‚Ø·Ø¹ÙŠ", "ØµØ­ÙŠØ­", "Ø­Ø³Ù†", "Ù…Ø®ØªÙ„Ù ÙÙŠÙ‡", "Ø¶Ø¹ÙŠÙ"])
    st.text_area("Ø®Ù„Ø§ØµØ© Ø§Ù„ØªØ­Ù‚ÙŠÙ‚")

    if st.button("â†©ï¸ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø¨Ø­Ø«"):
        go_to_search()
